---
title: "SOCS0100 Assessment 2"
format: html
editor: visual
---

## Part I-A

This assessment utilized static web-scraping in R to comprehensively gather data from FlixPatrol, which is a platform that collects streaming data about movies and TV shows (Eu-startups, 2026). The data that was scraped was the "Most Watched Movies and TV Shows from the United Kingdom in 2025 (January - June)", in order to understand cultural trends in the UK, media consumption patterns, and genre popularity.

The data was collected first by loading required packages as follows:

```{r}
# Setup
pacman::p_load(tidyverse, # tidyverse packages including purrr
               purrr, # automating 
               xml2, # parsing XML
               rvest, # parsing HTML
               robotstxt) #checking path is permitted 
```

However, before being able to scrape the data, the code below allowed to check whether this website was scrapable or not. Only once the code confirmed that the data could be scraped was the data collected and converted into a table called "table.df". A specific xpath of the table in the website was selected,

```{r}
#| echo: true
#| results: false
#| message: false
#| warning: false
# Checking if path is permitted 
paths_allowed(paths="https://flixpatrol.com/most-watched/2025-1/titles-from-united-kingdom/")

url <- "https://flixpatrol.com/most-watched/2025-1/titles-from-united-kingdom/"
parsed <- read_html(url) # This reads the HTML content of the page. 
parsed.sub <- html_element(parsed, xpath = '/html/body/div[4]/div[1]') # This extracts the specific xpath of the table containing the wanted most-watched data. 
```

```{r}
#| echo: false
#| message: false
#| warning: false
# Converting the data into a table
table.df <- html_table(parsed.sub) # This converts the extracted HTML table into an R dataframe.   
head(table.df)
```

## Part I-B

In this section, data wrangling and cleaning was carried out. Any empty rows were removed, and all names were cleaned into snake_case using the janitor package. Furthermore, in the "hours" and "views" columns, data were written twice in each individual cell so data cleaning also involved making sure that one cell only contained one value.

```{r}
#| echo: false
#| results: false
#| message: false
#| warning: false
# Rename the first column to "rank"
names(table.df)[1] <- "rank"

# Keeping all columns except "country" since it is all the UK
mostwatched_data <- table.df %>% select("rank", "title", "type", "premiere", "genre", "hours", "runtime", "views") # Dropping the "country" column since all data is for the UK.
head(mostwatched_data)

# Tidying data
library(janitor) # Loading the Janitor package.

# Cleaning names
names(mostwatched_data) <-  janitor::make_clean_names(names(mostwatched_data)) # This cleans all names into snake_case. 

# Deleting empty rows
empt <- apply(mostwatched_data, 1, FUN = function(x) all(is.na(x) | x == "")) # Removing missing values or empty rows. 
mostwatched_data <- mostwatched_data[which(!empt), ] 

head(mostwatched_data)

# Deleting the first row
mostwatched_data <- mostwatched_data[-1, ] # Removing the first row since it's empty. 

# Deleting the repeated second value in columns "hours" and "views"
mostwatched_data$views <- sub("\\s.*", "", mostwatched_data$views) # Each cell in "hours" and "views" had the same information written twice. This line thus keeps only one number. 
mostwatched_data$hours <- sub("\\s.*", "", mostwatched_data$hours)
```

```{r}
#| echo: true
#| results: false
#| message: false
#| warning: false
# Cleaning names
names(mostwatched_data) <-  janitor::make_clean_names(names(mostwatched_data)) # This cleans all names into snake_case. 

# Deleting empty rows
empt <- apply(mostwatched_data, 1, FUN = function(x) all(is.na(x) | x == "")) # Removing missing values or empty rows. 
mostwatched_data <- mostwatched_data[which(!empt), ]

# Deleting the repeated second value in columns "hours" and "views"
mostwatched_data$views <- sub("\\s.*", "", mostwatched_data$views) # Each cell in "hours" and "views" had the same information written twice. This line thus keeps only one number. 
mostwatched_data$hours <- sub("\\s.*", "", mostwatched_data$hours)
```

The following table was obtained after all data wrangling and cleaning process:

```{r}
#| label: fig-table
#| fig-cap: "Top Most Watched Titles (UK) Cleaned Table"
#| echo: false
#| message: false
#| warning: false
# Final table
library(kableExtra)
head(mostwatched_data, 5) |>
  kbl(caption = "Mostwatched TV shows/Movies UK", booktabs = TRUE) |>
  kable_styling(full_width = FALSE, position = "center")
```

@fig-table illustrates the rank, title, the date the movie/TV shows were premiered, genre, hours streamed, the length of the content, and the number of views. Media, especially those provided by the abundantly used Netflix platform, is easily accessible for most people. Today media not only shapes our perspectives and beliefs, but also mirrors societal preferences and culture. The genre of media and streaming preferences influences our knowledge and way of thinking, thus potentially influencing social behaviour. As a result, investigating streaming trends and patterns in social science is vital in order to understand individuals and culture, as it mirrors ourselves.

## Part II-A

In this second section, the refined dataset was used to produce 3 interactive visualisations dashboard on a Shiny app. The first visualisation method chosen was an bar chart showcasing the relationship between movie/TV show and the number of views/hours.

```{r}
#| echo: false
#| results: false
#| message: false
#| warning: false
# Creating "mostwatched_data" CSV for shiny app
write.csv(mostwatched_data, "mostwatched_data.csv", row.names = FALSE) # Exporting the cleaned "mostwatched_data" dataset as CSV for use in Shiny app
```

```{r}
#| label: fig-bar-chart-views
#| fig-cap: "Top Most Watched Titles (UK) by number of views"
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(dplyr)
library(scales)

df <- read.csv("mostwatched_data.csv")

df <- df %>%
  mutate(
    views = as.numeric(gsub(",", "", sub("\\s.*", "", views))),
    hours = as.numeric(gsub(",", "", sub("\\s.*", "", hours))),
    rank = as.numeric(rank)
  )

# Choose what you want to show
variable <- "views"     
top_n <- 10              # number of titles

fill_colour <- ifelse(variable == "views", "steelblue", "darkorange")

df %>%
  arrange(rank) %>%
  slice_head(n = top_n) %>%
  ggplot(aes(
    x = reorder(title, .data[[variable]]),
    y = .data[[variable]]
  )) +
  geom_col(fill = fill_colour) +
  coord_flip() +
  scale_y_continuous(labels = scales::comma) +
  labs(
    x = "Movie / TV show Title",
    y = variable,
    title = paste("Top", top_n, "Most Watched Titles (UK)"),
    subtitle = paste("Metric:", variable)
  ) +
  theme_minimal()
```

```{r}
#| label: fig-bar-chart-hours
#| fig-cap: "Top Most Watched Titles (UK) by hours watched"
#| echo: false
#| message: false
#| warning: false

library(ggplot2)
library(dplyr)
library(scales)

df <- read.csv("mostwatched_data.csv")

df <- df %>%
  mutate(
    views = as.numeric(gsub(",", "", sub("\\s.*", "", views))),
    hours = as.numeric(gsub(",", "", sub("\\s.*", "", hours))),
    rank = as.numeric(rank)
  )

# Choose what you want to show
variable <- "hours"     
top_n <- 10              # number of titles

fill_colour <- ifelse(variable == "views", "steelblue", "darkorange")

df %>%
  arrange(rank) %>%
  slice_head(n = top_n) %>%
  ggplot(aes(
    x = reorder(title, .data[[variable]]),
    y = .data[[variable]]
  )) +
  geom_col(fill = fill_colour) +
  coord_flip() +
  scale_y_continuous(labels = scales::comma) +
  labs(
    x = "Movie / TV show Title",
    y = variable,
    title = paste("Top", top_n, "Most Watched Titles (UK)"),
    subtitle = paste("Metric:", variable)
  ) +
  theme_minimal()
```

@fig-bar-chart-hours and @fig-bar-chart-views clearly presents the most popular titles in the UK by rank. These two bar charts gives us insight into patterns of media consumption. For instance, the TV show "Dept. Q" has a relatively low number of views compared to the show "Missing You", which ranks second in number of views. However, "Dept. Q" has a very similar number of hours watched as "Missing You". This reflects patterns of social consumption, also known as "binge-watching". In other words, some viewers in the UK enjoy to binge-watch media. While a low number of views may suggest low popularity at first glance, the number of hours watched indicates strong audience engagement.

However, the analysis done above can be applied to only certain titles. The general trend that data is showing is that titles with high number of views usually also have high number of hours watched as well. In summary, the bar charts informs us on popularity.
